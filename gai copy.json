{
    "gen": {
        "default": "mistral7b-exllama",
        "gpt-4": {
            "type": "ttt",
            "engine": "OpenAI_TTT",
            "api_key": "OPENAI_API_KEY",
            "hyperparameters": {
                "max_tokens": 100,
                "temperature": 0.7,
                "top_p": 1,
                "presence_penalty": 0.0,
                "frequency_penalty": 0.0,
                "stop": null,
                "logit_bias": {},
                "n": 1
            }
        },
        "mistral7b-exllama": {
            "type": "ttt",
            "model_name": "Mistral7B-ExLlama",
            "engine": "ExLlama_TTT",
            "model_path": "models/Mistral-7B-Instruct-v0.1-GPTQ",
            "model_basename": "model",
            "max_seq_len": 8192,
            "stopping_words": [],
            "hyperparameters": {
                "temperature": 1.2,
                "top_p": 0.15,
                "min_p": 0.0,
                "top_k": 50,
                "max_new_tokens": 1000,
                "typical": 0.0,
                "token_repetition_penalty_max": 1.25,
                "token_repetition_penalty_sustain": 256,
                "token_repetition_penalty_decay": 128,
                "beams": 1,
                "beam_length": 1
            }
        },
        "mistral7b_128k-exllama": {
            "type": "ttt",
            "model_name": "Mistral7B_128k-ExLlama",
            "engine": "ExLlamaV2_TTT",
            "model_path": "models/Yarn-Mistral-7B-128k-GPTQ",
            "model_basename": "model",
            "max_seq_len": 65536,
            "stopping_words": ["\n.+:"],
            "hyperparameters": {
                "temperature": 1.2,
                "top_p": 0.15,
                "min_p": 0.0,
                "top_k": 50,
                "max_new_tokens": 1000,
                "typical": 0.0,
                "token_repetition_penalty_max": 1.25,
                "token_repetition_penalty_sustain": 256,
                "token_repetition_penalty_decay": 128,
                "beams": 1,
                "beam_length": 1
            }
        },
        "claude2-100k": {
            "type": "ttt",
            "model_name": "Claude2",
            "engine": "Claude2_TTT",
            "api_key": "CLAUDE_API_KEY",
            "prompt_template": "\n\nHuman: {user_message}\n\nAssistant:",
            "hyperparameters": {
                "temperature": 0.9,
                "max_tokens_to_sample": 10000
            }
        },
        "mistral7b-llamacpp": {
            "type": "ttt",
            "model_name": "Mistral7B-LlamaCpp",
            "engine": "LlamaCpp_TTT",
            "model_path": "models/Mistral-7B-Instruct-v0.1-GGUF",
            "model_basename": "mistral-7b-instruct-v0.1.Q4_K_M.gguf",
            "max_seq_len": 8192,
            "stopping_words": [],
            "hyperparameters": {
                "max_tokens": 100,
                "temperature": 1.31,
                "top_k": 49,
                "top_p": 0.14
            }
        },
        "llama2-transformers": {
            "type": "ttt",
            "model_name": "LlaMa2-7B",
            "engine": "Transformers_TTT",
            "model_path": "models/Llama-2-7b-chat-hf",
            "model_basename": "",
            "max_seq_len": 2048,
            "stopping_words": [],
            "hyperparameters": {
                "max_new_tokens": 1024,
                "temperature": 1.31,
                "top_k": 49,
                "top_p": 0.14,
                "do_sample": true
            }
        },
        "deepseek-transformers": {
            "type": "ttt",
            "engine": "Transformers_TTT",
            "model_path": "models/deepseek-coder-6.7b-instruct",
            "model_basename": ""
        },
        "openai-whisper": {
            "type": "stt",
            "engine": "OpenAIWhisper_STT",
            "model_name": "OpenAI Whisper v1",
            "api_key": "OPENAI_API_KEY"
        },
        "whisper-transformers": {
            "type": "stt",
            "engine": "LocalWhisper_STT",
            "model_name": "OpenAI Whisper v3",
            "model_path": "models/whisper-large-v3",
            "model_basename": "",
            "max_seq_len": 128,
            "stopping_words": [],
            "hyperparameters": {
                "chunk_length_s": 30,
                "batch_size": 16,
                "max_new_tokens": 128
            }
        },
        "openai-tts-1": {
            "type": "tts",
            "engine": "OpenAI_TTS",
            "api_key": "OPENAI_API_KEY"
        },
        "xtts-2": {
            "type": "tts",
            "engine": "XTTS_TTS",
            "model_name": "Coqui TTS v2",
            "model_path": "models/tts/tts_models--multilingual--multi-dataset--xtts_v2",
            "model_basename": "",
            "max_seq_len": 128,
            "stopping_words": []
        },
        "openai-vision": {
            "type": "itt",
            "engine": "Vision_ITT",
            "model_name": "OpenAI Vision",
            "api_key": "OPENAI_API_KEY",
            "hyperparameters": {
                "temperature": 0.2,
                "max_tokens": 512
            }
        },
        "llava-transformers": {
            "type": "itt",
            "engine": "Llava_ITT",
            "model_name": "llava-v1.5-7b",
            "model_path": "models/llava-v1.5-7b",
            "model_basename": "llava-v1.5-7b",
            "max_seq_len": 128,
            "stopping_words": [],
            "model_base": null,
            "load_8bit": false,
            "load_4bit": true,
            "image_aspect_ratio": "pad",
            "hyperparameters": {
                "temperature": 0.2,
                "max_new_tokens": 512
            }
        },
        "rag": {
            "type": "rag",
            "chromadb": {
                "path": "chromadb",
                "n_results": 3
            },
            "model_path": "models/instructor-large",
            "device": "cuda",
            "chunks": {
                "size": 2000,
                "overlap": 200,
                "path": "chunks"
            }
        }
    }
}
