{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gai/Gen: Speech-to-Text (STT)\n",
    "\n",
    "## 1. Note\n",
    "\n",
    "The following examples has been tested on the following environment:\n",
    "\n",
    "-   NVidia GeForce RTX 2060 6GB\n",
    "-   Windows 11 + WSL2\n",
    "-   Ubuntu 22.04\n",
    "-   Python 3.10\n",
    "-   CUDA Toolkit 11.8\n",
    "-   openai 1.6.1\n",
    "-   transformers 4.36.2\n",
    "-   accelerate 0.25.0\n",
    "\n",
    "\n",
    "## 2. Create Virtual Environment and Install Dependencies\n",
    "\n",
    "We will create a seperate virtual environment for this to avoid conflicting dependencies that each underlying model requires.\n",
    "\n",
    "```sh\n",
    "sudo apt update -y && sudo apt install ffmpeg git git-lfs -y\n",
    "conda create -n STT python=3.10.10 -y\n",
    "conda activate STT\n",
    "pip install -e \".[STT]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "huggingface-cli download openai/whisper-large-v3 \\\n",
    "        --local-dir ~/gai/models/whisper-large-v3 \\\n",
    "        --local-dir-use-symlinks False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING:\n",
      "Transcription(text='Tell me a one-paragraph story.')\n",
      "Transcription(text='Tell me a one-paragraph story.')\n",
      "Transcription(text='Tell me a one-paragraph story.')\n"
     ]
    }
   ],
   "source": [
    "## 6.12 OpenAI Whisper Speech-to-Text\n",
    "\n",
    "print(\"GENERATING:\")\n",
    "from gai.gen import Gaigen\n",
    "from pathlib import Path\n",
    "gen = Gaigen.GetInstance().load('openai-whisper')\n",
    "\n",
    "# Method 1: Using Path\n",
    "response = gen.create(\n",
    "  file=Path(\"../tests/gen/stt/tell-me-a-one-paragraph-story.wav\")\n",
    ")\n",
    "print(response)\n",
    "\n",
    "# Method 2: Using File\n",
    "file = open(\"../tests/gen/stt/tell-me-a-one-paragraph-story.wav\", \"rb\")\n",
    "response = gen.create(\n",
    "  file=file\n",
    ")\n",
    "print(response)\n",
    "\n",
    "# Method 3: Using Bytes (Not-In-Spec)\n",
    "file = open(\"../tests/gen/stt/tell-me-a-one-paragraph-story.wav\", \"rb\")\n",
    "data = file.read()\n",
    "response = gen.create(\n",
    "  file=data\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING:\n",
      "Transcription(text='Today is a wonderful day to build something people love.')\n",
      "Transcription(text='Today is a wonderful day to build something people love.')\n",
      "Transcription(text='Today is a wonderful day to build something people love.')\n"
     ]
    }
   ],
   "source": [
    "## 6.13 Open-Sourced Whisper Speech-to-Text\n",
    "\n",
    "print(\"GENERATING:\")\n",
    "from gai.gen import Gaigen\n",
    "from pathlib import Path\n",
    "gen = Gaigen.GetInstance().load('whisper-transformers')\n",
    "\n",
    "# Method 1: Using Path\n",
    "response = gen.create(\n",
    "  file=Path(\"../tests/gen/stt/today-is-a-wonderful-day.wav\")\n",
    ")\n",
    "print(response)\n",
    "\n",
    "# Method 2: Using File\n",
    "file = open(\"../tests/gen/stt/today-is-a-wonderful-day.wav\", \"rb\")\n",
    "response = gen.create(\n",
    "  file=file\n",
    ")\n",
    "print(response)\n",
    "\n",
    "# Method 3: Using Bytes (Not-In-Spec)\n",
    "file = open(\"../tests/gen/stt/today-is-a-wonderful-day.wav\", \"rb\")\n",
    "data = file.read()\n",
    "response = gen.create(\n",
    "  file=data\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running as a Service\n",
    "\n",
    "#### Step 1: Start Docker container\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "    --name gai-stt \\\n",
    "    -p 12031:12031 \\\n",
    "    --gpus all \\\n",
    "    -v ~/gai/models:/app/models \\\n",
    "    kakkoii1337/gai-stt:latest\n",
    "```\n",
    "\n",
    "#### Step 2: Wait for model to load\n",
    "\n",
    "```bash\n",
    "docker logs gai-stt\n",
    "```\n",
    "\n",
    "When the loading is completed, the logs should show this:\n",
    "\n",
    "```bash\n",
    "INFO:     Started server process [1]\n",
    "INFO:     Waiting for application startup.\n",
    "INFO:     Application startup complete.\n",
    "INFO:     Uvicorn running on http://0.0.0.0:12031 (Press CTRL+C to quit)\n",
    "```\n",
    "\n",
    "#### Step 3: Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\":\" Today is a wonderful day to build something people love.\",\"chunks\":[{\"timestamp\":[0.0,3.14],\"text\":\" Today is a wonderful day to build something people love.\"}]}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -X 'POST' \\\n",
    "'http://localhost:12031/gen/v1/audio/transcriptions' \\\n",
    "    -H 'accept: application/json' \\\n",
    "    -H 'Content-Type: multipart/form-data' \\\n",
    "    -s \\\n",
    "    -F 'file=@../tests/gen/stt/today-is-a-wonderful-day.wav' \\\n",
    "    -F 'model=whisper-transformers'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TTT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
