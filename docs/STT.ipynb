{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gai/Gen: Speech-to-Text (STT)\n",
    "\n",
    "## 1. Note\n",
    "\n",
    "The following examples has been tested on the following environment:\n",
    "\n",
    "-   NVidia GeForce RTX 2060 6GB\n",
    "-   Windows 11 + WSL2\n",
    "-   Ubuntu 22.04\n",
    "-   Python 3.10\n",
    "-   CUDA Toolkit 11.8\n",
    "-   openai 1.6.1\n",
    "-   transformers 4.36.2\n",
    "-   accelerate 0.25.0\n",
    "\n",
    "\n",
    "## 2. Create Virtual Environment and Install Dependencies\n",
    "\n",
    "We will create a seperate virtual environment for this to avoid conflicting dependencies that each underlying model requires.\n",
    "\n",
    "```sh\n",
    "sudo apt update -y && sudo apt install ffmpeg git git-lfs -y\n",
    "conda create -n STT python=3.10.10 -y\n",
    "conda activate STT\n",
    "pip install gai-gen[STT]\n",
    "```\n",
    "\n",
    "## 3. Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING:\n",
      "Transcription(text='Tell me a one-paragraph story.')\n",
      "Transcription(text='Tell me a one-paragraph story.')\n",
      "Transcription(text='Tell me a one-paragraph story.')\n"
     ]
    }
   ],
   "source": [
    "## 6.12 OpenAI Whisper Speech-to-Text\n",
    "\n",
    "print(\"GENERATING:\")\n",
    "from gai.gen import Gaigen\n",
    "from pathlib import Path\n",
    "gen = Gaigen.GetInstance().load('openai-whisper')\n",
    "\n",
    "# Method 1: Using Path\n",
    "response = gen.create(\n",
    "  file=Path(\"../tests/tell-me-a-one-paragraph-story.wav\")\n",
    ")\n",
    "print(response)\n",
    "\n",
    "# Method 2: Using File\n",
    "file = open(\"../tests/tell-me-a-one-paragraph-story.wav\", \"rb\")\n",
    "response = gen.create(\n",
    "  file=file\n",
    ")\n",
    "print(response)\n",
    "\n",
    "# Method 3: Using Bytes (Not-In-Spec)\n",
    "file = open(\"../tests/tell-me-a-one-paragraph-story.wav\", \"rb\")\n",
    "data = file.read()\n",
    "response = gen.create(\n",
    "  file=data\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example uses OpenAI's open-sourced WhisperV3 model. You can download it from hugging face using commands below.\n",
    "\n",
    "```\n",
    "sudo git config --global lfs.largefilewarning false\n",
    "git clone https://huggingface.co/openai/whisper-large-v3 ~/gai/models/whisper-large-v3\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/roylai/miniconda/envs/STT/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Attempt to open cnn_infer failed: handle=0 error: libcudnn_cnn_infer.so.8: cannot open shared object file: No such file or directory (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:78.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' Today is a wonderful day to build something people love.', 'chunks': [{'timestamp': (0.0, 3.14), 'text': ' Today is a wonderful day to build something people love.'}]}\n",
      "{'text': ' Today is a wonderful day to build something people love.', 'chunks': [{'timestamp': (0.0, 3.14), 'text': ' Today is a wonderful day to build something people love.'}]}\n",
      "{'text': ' Testing testing 1 2 3', 'chunks': [{'timestamp': (0.0, 2.7), 'text': ' Testing testing 1 2 3'}]}\n"
     ]
    }
   ],
   "source": [
    "## 6.13 Open-Sourced Whisper Speech-to-Text\n",
    "\n",
    "print(\"GENERATING:\")\n",
    "from gai.gen import Gaigen\n",
    "from pathlib import Path\n",
    "gen = Gaigen.GetInstance().load('whisper-transformers')\n",
    "\n",
    "# Method 1: Using Path\n",
    "response = gen.create(\n",
    "  file=Path(\"../tests/today-is-a-wonderful-day.wav\")\n",
    ")\n",
    "print(response)\n",
    "\n",
    "# Method 2: Using File\n",
    "file = open(\"../tests/today-is-a-wonderful-day.wav\", \"rb\")\n",
    "response = gen.create(\n",
    "  file=file\n",
    ")\n",
    "print(response)\n",
    "\n",
    "# Method 3: Using Bytes (Not-In-Spec)\n",
    "file = open(\"../tests/today-is-a-wonderful-day.wav\", \"rb\")\n",
    "data = file.read()\n",
    "response = gen.create(\n",
    "  file=data\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running as a Service\n",
    "\n",
    "#### Step 1: Start Docker container\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "    --name gai-stt \\\n",
    "    -p 12031:12031 \\\n",
    "    --gpus all \\\n",
    "    -v ~/gai/models:/app/models \\\n",
    "    kakkoii1337/gai-stt:latest\n",
    "```\n",
    "\n",
    "#### Step 2: Wait for model to load\n",
    "\n",
    "```bash\n",
    "docker logs gai-stt\n",
    "```\n",
    "\n",
    "When the loading is completed, the logs should show this:\n",
    "\n",
    "```bash\n",
    "INFO:     Started server process [1]\n",
    "INFO:     Waiting for application startup.\n",
    "INFO:     Application startup complete.\n",
    "INFO:     Uvicorn running on http://0.0.0.0:12031 (Press CTRL+C to quit)\n",
    "```\n",
    "\n",
    "#### Step 3: Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl -X 'POST' \\\n",
    "'http://localhost:12031/gen/v1/audio/transcriptions' \\\n",
    "    -H 'accept: application/json' \\\n",
    "    -H 'Content-Type: multipart/form-data' \\\n",
    "    -s \\\n",
    "    -F 'file=@../today-is-a-wonderful-day.wav' \\\n",
    "    -F 'model=whisper-transformers'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TTT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
