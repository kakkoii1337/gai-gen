{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gai/Gen: Retrieval-Augmented-Generation (RAG)\n",
    "\n",
    "## 1. Note\n",
    "\n",
    "The following examples has been tested on the following environment:\n",
    "\n",
    "-   NVidia GeForce RTX 2060 6GB\n",
    "-   Windows 11 + WSL2\n",
    "-   Ubuntu 22.04\n",
    "-   Python 3.10\n",
    "-   CUDA Toolkit 11.8\n",
    "\n",
    "## 2. Create Virtual Environment and Install Dependencies\n",
    "\n",
    "We will create a seperate virtual environment for this to avoid conflicting dependencies that each underlying model requires.\n",
    "\n",
    "```sh\n",
    "sudo apt update -y && sudo apt install ffmpeg git git-lfs -y\n",
    "conda create -n RAG python=3.10.10 -y\n",
    "conda activate RAG\n",
    "pip install -e \".[RAG]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "huggingface-cli download hkunlp/instructor-large \\\n",
    "        --local-dir ~/gai/models/instructor-large \\\n",
    "        --local-dir-use-symlinks False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset 'demo' collection\n",
    "from gai.gen.rag import RAG\n",
    "RAG.delete_collection(\"demo\")\n",
    "RAG.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index a long speech\n",
    "import asyncio\n",
    "from gai.gen.Gaigen import Gaigen\n",
    "gen = Gaigen.GetInstance().load('rag')\n",
    "with open(\"../tests/gen/rag/pm_long_speech_2023.txt\") as f:\n",
    "    text = f.read()\n",
    "doc_id = None\n",
    "async def run_indexing(text):\n",
    "    global doc_id\n",
    "    doc_id = await gen.index_async(collection_name=\"demo\",text=text, path_or_url=\"2023 National Day Speech\", metadata={\n",
    "        \"source\":\"https://www.pmo.gov.sg/Newsroom/2023-National-Day-Rally-Speech\",\n",
    "        \"title\" : \"2023 National Day Rally Speech\",\n",
    "        })\n",
    "    print(f\"Indexed document with id {doc_id}\")\n",
    "\n",
    "asyncio.create_task(run_indexing(text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gai.gen.rag import RAG\n",
    "rag = RAG()\n",
    "docs = rag.list_documents(\"demo\")\n",
    "for doc in docs:\n",
    "    print(doc.Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = rag.get_document(doc_id)\n",
    "print(doc.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve answers\n",
    "from gai.gen.Gaigen import Gaigen\n",
    "gen = Gaigen.GetInstance().load('rag')\n",
    "result=gen.retrieve(collection_name=\"demo\",query_texts=\"Who are the young seniors?\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index and Retrieve PDF\n",
    "\n",
    "from gai.common.PDFConvert import PDFConvert\n",
    "from gai.common.utils import this_dir, os\n",
    "import asyncio\n",
    "\n",
    "src = \"../tests/unit_tests/common/attention-is-all-you-need.pdf\"\n",
    "text=PDFConvert.pdf_to_text(src,False)\n",
    "gen = Gaigen.GetInstance().load('rag')\n",
    "\n",
    "async def index_and_retrieve():\n",
    "    await gen.index_async(collection_name=\"demo\",text=text, path_or_url=src, metadata={\"source\":src})\n",
    "    result=gen.retrieve(collection_name=\"demo\",query_texts=\"How is the transformer different from RNN?\")\n",
    "    print(result)\n",
    "\n",
    "asyncio.create_task(index_and_retrieve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Running as a Service\n",
    "\n",
    "#### Step 1: Start Docker container\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "    --name gai-rag \\\n",
    "    -p 12031:12031 \\\n",
    "    --gpus all \\\n",
    "    -v ~/gai/models:/app/models \\\n",
    "    kakkoii1337/gai-rag:latest\n",
    "```\n",
    "\n",
    "#### Step 2: Wait for model to load\n",
    "\n",
    "```bash\n",
    "docker logs gai-rag\n",
    "```\n",
    "\n",
    "When the loading is completed, the logs should show this:\n",
    "\n",
    "```bash\n",
    "INFO:     Started server process [1]\n",
    "INFO:     Waiting for application startup.\n",
    "INFO:     Application startup complete.\n",
    "INFO:     Uvicorn running on http://0.0.0.0:12031 (Press CTRL+C to quit)\n",
    "```\n",
    "\n",
    "#### Step 3: Test\n",
    "\n",
    "The listener can be used to monitor the indexing progress via web socket. This is especially useful when indexing large files.\n",
    "\n",
    "**Start Listening**\n",
    "\n",
    "```bash\n",
    "cd tests/gen/rag\n",
    "python function_test_websocket_listener.py\n",
    "```\n",
    "\n",
    "**Send Request**\n",
    "\n",
    "```bash\n",
    "cd tests/gen/rag\n",
    "./curl_index.sh\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Static Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demo']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all collections (api)\n",
    "from gai.gen.rag import RAG\n",
    "RAG.list_collections()\n",
    "[collection.name for collection in RAG.list_collections()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '07ab5070-a065-4748-87e3-c97b0e17f5d9',\n",
       "  'title': '2023 National Day Rally Speech',\n",
       "  'size': 43153,\n",
       "  'chunk_count': 29,\n",
       "  'chunk_size': 2000,\n",
       "  'overlap_size': 200,\n",
       "  'source': 'https://www.pmo.gov.sg/Newsroom/2023-National-Day-Rally-Speech'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all documents in collection (api)\n",
    "from gai.gen.rag import RAG\n",
    "docs = RAG.list_documents(\"demo\")\n",
    "last_doc_id = docs[-1].Id\n",
    "[{\"id\":doc.Id,\"title\":doc.Title,\"size\":doc.ByteSize,\"chunk_count\":doc.ChunkCount,\"chunk_size\":doc.ChunkSize,\"overlap_size\":doc.Overlap,\"source\":doc.Source} for doc in docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all chunks in collection\n",
    "from gai.gen.rag import RAG\n",
    "RAG.list_chunks(\"demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState at 0x7f9417f28ac0>,\n",
       " 'Id': '07ab5070-a065-4748-87e3-c97b0e17f5d9',\n",
       " 'Abstract': '',\n",
       " 'UpdatedAt': datetime.datetime(2024, 2, 10, 1, 15, 24, 484191),\n",
       " 'ChunkCount': 29,\n",
       " 'Authors': '',\n",
       " 'ByteSize': 43153,\n",
       " 'Title': '2023 National Day Rally Speech',\n",
       " 'ChunkSize': 2000,\n",
       " 'Publisher': None,\n",
       " 'Overlap': 200,\n",
       " 'PublishedDate': None,\n",
       " 'SplitAlgo': None,\n",
       " 'Comments': '',\n",
       " 'FileName': '',\n",
       " 'IsActive': True,\n",
       " 'CollectionName': 'demo',\n",
       " 'Source': 'https://www.pmo.gov.sg/Newsroom/2023-National-Day-Rally-Speech',\n",
       " 'CreatedAt': datetime.datetime(2024, 2, 10, 1, 15, 24, 484187),\n",
       " 'chunks': [<gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478310>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478370>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c4783d0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478430>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478490>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c4784f0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478550>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c4785b0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478610>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478670>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c4786d0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478730>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478790>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c4787f0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478850>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c4788b0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478910>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478970>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c4789d0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478a30>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478a90>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478af0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478b50>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478bb0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478c10>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478c70>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c478cd0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c4847c0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c484a60>]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get one document\n",
    "from gai.gen.rag import RAG\n",
    "doc = RAG.get_document(last_doc_id)\n",
    "doc.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState at 0x7f9417f4ebc0>,\n",
       " 'Id': '07ab5070-a065-4748-87e3-c97b0e17f5d9',\n",
       " 'Abstract': '',\n",
       " 'UpdatedAt': datetime.datetime(2024, 2, 10, 1, 44, 55, 589924),\n",
       " 'ChunkCount': 29,\n",
       " 'Authors': '',\n",
       " 'ByteSize': 43153,\n",
       " 'Title': 'Attention is all you need',\n",
       " 'ChunkSize': 2000,\n",
       " 'Publisher': None,\n",
       " 'Overlap': 200,\n",
       " 'PublishedDate': None,\n",
       " 'SplitAlgo': None,\n",
       " 'Comments': '',\n",
       " 'FileName': '',\n",
       " 'IsActive': True,\n",
       " 'CollectionName': 'demo',\n",
       " 'Source': 'https://www.pmo.gov.sg/Newsroom/2023-National-Day-Rally-Speech',\n",
       " 'CreatedAt': datetime.datetime(2024, 2, 10, 1, 15, 24, 484187),\n",
       " 'chunks': [<gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c4877c0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487820>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487880>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c4878e0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487940>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c4879a0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487a00>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487a60>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487ac0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487b20>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487b80>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487be0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487c40>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487ca0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487d00>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487d60>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487dc0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487e20>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487e80>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487ee0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487f40>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c487fa0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c48a080>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c489c00>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c488070>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c4880d0>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c488130>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c488190>,\n",
       "  <gai.gen.rag.models.IndexedDocumentChunk.IndexedDocumentChunk at 0x7f941c4881f0>]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update document\n",
    "from gai.gen.rag import RAG\n",
    "doc.Title = \"Attention is all you need\"\n",
    "doc.Source = \"https://arxiv.org/abs/1706.03762\"\n",
    "doc.Authors = \"Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\"\n",
    "doc.Abstract = \"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\"\n",
    "doc.PublishedDate = \"2017-Jun-12\"\n",
    "\n",
    "RAG.update_document(doc)\n",
    "RAG.get_document(last_doc_id).__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0b7c01468ca7505ef751e06647b17d0475d51813c3a1925590df81a7a4b5a3a7\n",
      "53bfb1d80c93baf656446d5c5257e79163a771f414351902244e6d2f2e6c88c9\n",
      "8aa8cc17c40a9a090458c6725cd16cdae0cdf5d311e7b935affb461f1877a287\n",
      "d96cc56503db04cfa4f6c10fd39aa3250f6e1a3c0ff9b85a119585b8a7d92df4\n",
      "eafa20be8f5a92207f25cfd85774fbb436f53d5851c16d8bfac8cab47e0b2559\n",
      "b9210565cbd269027dd0b19e91c3ab7db415670c088c0cada970c970a165f784\n",
      "5d61c4ead1186f6de6909eca57f6675c789e43b09cfec6b738cb802b7b4eea69\n",
      "f5b54668d2357185abda3d81ceda8d1218b230100a483e58e45c94d8765432ef\n",
      "55e2cfde42f2e10abd85d1c5a0135cdf89138472bf18e390d768cc5eca919389\n",
      "57d3f5af7dd4bf93488fe5e837e22591b53513ab7faa9199ef91a066bae13f31\n",
      "5f400f3e27f615c6663d4f355745b58ecc9730380d74726e13e8731251c67e16\n",
      "2487f6e4cc193ca3b9c7f0b961b0d47f5d28dd0ca7df5cfb6e8f276f452ed834\n",
      "73ffba02a444eb4ded0bb5f1e6258660ede0897b8aff611bec1b5e2c269c9b68\n",
      "0c494f2a001a0666487734f76141fd75fb0d570c4fcc9e1463cc31c8bf2eeaca\n",
      "b14b2128be165ff7195c08914cc11f9203888392776b80867ff7594e4b49df1f\n",
      "d040a9e16a818fd6598483721a043a3a22bf9dca24bf35d0cf4e8ae4cf728e81\n",
      "243a269e5895fef77afcc4dbbbe74aeef919944018b2ae2e2bd6537ed6640b42\n",
      "dcfa12bb04a5a0b40a5bfee4bab4db230c9b64c0783ce1759c924b15364e5b0b\n",
      "867b511eb966cd9e89e29416be744feb6cc7df43209a07f6cf160f23c218f065\n",
      "1eaa155a661d38285024eb5b5c217bc930404bf943d8ebb445b87dedd1ddbafd\n",
      "87633d7b1d93651484d23cecb762900b9c97db67fdc998f60375feac4e5df67a\n",
      "b84387fd63d314d528e1a1bd85e3e4edbeb2f99c3ef241e8c400bb5145cf418d\n",
      "94f0f70f5a0ec555696a1bac479d55533734d89fcfa4913637ecfa56b5d3f5bd\n",
      "17ec7d5812b3efd303a797663196ab70ed36e913908f232aca68c234f13332d2\n",
      "cead4552077c85ef19d06a425c2297547c513718a8fabac782ef824f0332da71\n",
      "5255ad964d5937cfbd77330e4ade51be36591644e1184594bcb73ed1c77af8ca\n",
      "df8c6b5c94e406bcfa45293d0e4e82866a12f9b07a2b5cf11cd835d155eb5a93\n",
      "a3cbfc46792960e682376932bc02b7a43508c7f5dcf97934dd2be978c8091889\n",
      "6f86ccc47643496442273b3c4d397661c5063972750efee125082385f113099a\n"
     ]
    }
   ],
   "source": [
    "# Get all chunks of a document\n",
    "from gai.gen.rag import RAG\n",
    "chunks = RAG.get_document(last_doc_id).chunks\n",
    "last_chunk_id = None\n",
    "for chunk in chunks:\n",
    "    last_chunk_id = chunk.ChunkId\n",
    "    print(chunk.ChunkId)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a chunk by id\n",
    "from gai.gen.rag import RAG\n",
    "RAG.get_chunk(\"demo\",last_chunk_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete document\n",
    "from gai.gen.rag import RAG\n",
    "RAG.delete_document(last_doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete collection (done)\n",
    "from gai.gen.rag import RAG\n",
    "RAG.delete_collection('demo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gai-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
